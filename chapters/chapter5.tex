\part{目标检测}
\chapter{基本概念}

\section{指标}

\subsection{交并比}
交并比（Intersection over Union，IoU）

\section{非极大值抑制}

非极大值抑制（Non maximum suppression，NMS）是一种后处理方法，其作用是保证一个待
检测物体只有一个检测框与之对应，更直观地理解其实是极大值保留，即只保留（置信度）
是极大值的检测框。图~\ref{fig:nms}~给出了一个具体示例\citerb{2018-NMS}：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/NMS.png}
  \caption{NMS 示例}
  \label{fig:nms}
\end{figure}

\subsection{传统 NMS}

传统 NMS 算法的具体流程是，先根据分数对所有检测框进行排序，然后从分高到分低遍历所
有检测框，如果高分检测框与低分检测框的 IoU 大于一定阈值，则将低分检测框删掉，后续
遍历时不再处理，如图~\ref{fig:nms-algo}~中的红框。

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{images/目标检测/Soft-NMS.pdf}
  \caption{NMS 和 Soft NMS 算法流程}
  \label{fig:nms-algo}
\end{figure}

\subsection{Soft NMS}

传统 NMS 算法需要选择合适的两个检测框的 IoU 阈值，否则阈值太低会导致误检，而阈值
太高又会导致漏检。Soft NMS 的基本思想是根据两个检测框的 IoU，降低低分检测框的分
数，但并不直接将其删除，具体形式如图~\ref{fig:nms-algo}~中的绿框~\citerb{2017-Soft-NMS}。

\subsection{Softer NMS}
文献~\citerb{2018-Softer-NMS}~中在 Soft NMS 的基础上提出了 Softer NMS，具体流程
如图~\ref{fig:softer-nms}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{images/目标检测/Softer-NMS.pdf}
  \caption{Softer NMS 算法流程}
  \label{fig:softer-nms}
\end{figure}

由图~\ref{fig:softer-nms}~可知，Softer NMS 在 Soft NMS 基础上，加入了 var voting
的部分，其具体步骤是：

\begin{enumerate}
  \item 对任一检测框，计算所有分数低于该框的检测框与其的 IoU。
  \item 根据 IoU 和每个检测框的不确定度 $\sigma$，修正该检测框的位置，其中 IoU
    越大，$ \sigma $ 越小，则相应的权重越高。
\end{enumerate}

\chapter{两阶段方法}

\chapter{单阶段方法}

\section{YOLO 系列}
\label{sec:YOLO}

\subsection{YOLO v1}
\label{subsec:YOLOv1}
YOLO v1 将检测问题全部用回归问题描述，没有任何分类的部分。

\subsubsection{检测方法}
YOLO v1 的检测方法如下：

\begin{enumerate}
  \item 将整张图片划分为 $S \times S$ 个网格，每个网格预测 $ B $ 个检测框和 $ C $
  个条件概率 $ \mathrm{Pr}(\mathrm{Class_i}|\mathrm{Object}) $。
  \item 每个 bounding box 共包括 5 个值 $x, y, w, h$ 和 confidence。其中 $x, y$为中
  心位置，$w, h$ 为长和宽(相对图片而言)，confidence 为$\mathrm{Pr}(\mathrm{Object}) \times
  \mathrm{IoU}^{\mathrm{truth}}_{\mathrm{pred}}$，inference 时直接将 confidence
  乘以该网格对应的条件概率得到最终的分数。因此网络最终的输出维度为 $ S \times S
  \times (B \times 5 + C) $。
\end{enumerate}


\subsubsection{Backbone}
YOLO v1 的 backbone 没有采用改造的经典分类网络，而是采用结构为 24 个卷积层 + 2 个
全连接层的自己设计的网络。训练时，先将前 20 个卷积层 + 平均池化层组成的网络
在 ImageNet 数据集上进行预训练，输入尺寸为 $224 \times 224$，在检测时将尺寸扩大
为 $448 \times 448$。

\subsubsection{Loss 函数}

YOLO v1 使用的 loss 函数为：
\begin{align}
  \label{equ:yolo-v1-loss}
  \begin{split}
    L = & \, \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left [ \left (x_i - \hat{x}_i \right )^2 + \left (y_i - \hat{y}_i \right )^2 \right ] + \\
    & \, \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left [ \left(\sqrt{w_i} - \sqrt{\hat{w}_i} \right)^2 + \left (\sqrt{h_i} - \sqrt{\hat{h}_i} \right )^2 \right ] + \\
    & \, \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left( C_i - \hat{C}_i \right)^2 + \\
    & \, \lambda_{\mathrm{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{noobj}} \left( C_i - \hat{C}_i \right)^2 + \\
    & \, \sum_{i=0}^{S^2} \mathds{1}_{i}^{\mathrm{obj}} \sum_{c \in \mathrm{classes}} \left( p_i(c) - \hat{p}_i(c) \right)^2
  \end{split}
\end{align}

\subsection{YOLO v2}
\label{subsec:YOLOv2}

\subsection{YOLO v3}
\label{subsec:YOLOv3}

\section{SSD 系列}
\label{sec:SSD}

\subsection{SSD}
\label{subsec:SSD}

\subsection{DSSD}
\label{subsec:DSSD}

\chapter{Anchor Free 方法}


%%% Local Variables:
%%% TeX-master: "../master"
%%% End:
