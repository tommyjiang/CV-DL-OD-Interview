\part{目标检测}
\chapter{基本概念}

\section{指标}

\subsection{交并比（IoU）}
交并比（Intersection over Union，IoU）是衡量两个矩形接近程度的一种指标，其定义为：
\begin{equation}
  \label{equ:IoU}
  \mathrm{IoU} = \frac{\mathrm{Intersection}(A, B)}{\mathrm{union}(A, B)}
\end{equation}

\subsection{mAP}
mAP 全称为 Mean Average Precision，中文一般不进行翻译。

\section{非极大值抑制（NMS）}

非极大值抑制（Non maximum suppression，NMS）是一种后处理方法，其作用是保证一个待
检测物体只有一个检测框与之对应，更直观地理解其实是极大值保留，即只保留（置信度）
是极大值的检测框。图~\ref{fig:nms}~给出了一个具体示例\citerb{2018-NMS}：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/NMS.pdf}
  \caption{NMS 示例}
  \label{fig:nms}
\end{figure}

\subsection{传统 NMS}

传统 NMS 算法的具体流程是，先根据分数对所有检测框进行排序，然后从分高到分低遍历所
有检测框，如果高分检测框与低分检测框的 IoU 大于一定阈值，则将低分检测框删掉，后续
遍历时不再处理，如图~\ref{fig:nms-algo}~中的红框。

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{images/目标检测/Soft-NMS.pdf}
  \caption{NMS 和 Soft NMS 算法流程}
  \label{fig:nms-algo}
\end{figure}

\subsection{Soft NMS}

传统 NMS 算法需要选择合适的两个检测框的 IoU 阈值，否则阈值太低会导致误检，而阈值
太高又会导致漏检。Soft NMS 的基本思想是根据两个检测框的 IoU，降低低分检测框的分
数，但并不直接将其删除，具体形式如图~\ref{fig:nms-algo}~中的绿
框~\citerb{2017-Soft-NMS}。其中 $f(iou(M, b_i))$ 的形式为：
\begin{equation}
f(iou(M, b_i)) = e^{-\frac{\mathrm{iou}(M, b_i)^2}{\sigma}}
\end{equation}

即两个框的 IoU 越大，分数较低框的分数降低的越多。

\subsection{Softer NMS}
文献~\citerb{2018-Softer-NMS}~中在 Soft NMS 的基础上提出了 Softer NMS，具体流程
如图~\ref{fig:softer-nms}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.5\textwidth]{images/目标检测/Softer-NMS.pdf}
  \caption{Softer NMS 算法流程}
  \label{fig:softer-nms}
\end{figure}

由图~\ref{fig:softer-nms}~可知，Softer NMS 在 Soft NMS 基础上，加入了 var voting
的部分，其具体步骤是：

\begin{enumerate}
  \item 对任一检测框，计算所有分数低于该框的检测框与其的 IoU。
  \item 根据 IoU 和每个检测框的不确定度 $\sigma$，修正该检测框的位置，其中 IoU
    越大，$ \sigma $ 越小，则相应的权重越高。
\end{enumerate}

\chapter{两阶段方法}
\section{R-CNN 系列}
\label{sec:R-CNN}

\subsection{Fast R-CNN}
\label{subsec:Fast-R-CNN}

Fast R-CNN 在训练和测试时，只需要利用 CNN 将整张图片前传一次，不需要像 R-CNN 中
将所有 proposal 对应的图片区域先 resize 再进行前传，因此可以大大提升训练和测试速
度\citerb{2015-Fast-RCNN}。

\paragraph{网络结构} 
Fast R-CNN 的网络结构如图~\ref{fig:Fast-RCNN}~所示，前面是统一的 CNN backbone，对
于每个 proposal，将其投射到 feature map 再经过 RoI pooling 层得到尺寸为 $h
\times w$ 的 RoI，再经过两个全连接层得到 RoI feature，再经过全连接层 + Softmax 层
的分类器得到分类分数（共 $C+1$ 类，多一个背景类），同时 RoI feature 也会经过全连
接层得到回归变换值（$t_x, t_y, t_w, t_h$四个值）。

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/Fast-RCNN.pdf}
  \caption{Fast R-CNN 网络结构}
  \label{fig:Fast-RCNN}
\end{figure}

\paragraph{RoI Pooling 层}
RoI 全称为 Region of Interest，中文可译为感兴趣区域。RoI Pooling 层的作用是将大小不一
的proposal 统一转化为 $h \times w$ 的尺寸，作为后续全连接层的输入。全连接层要求输
入为固定的尺寸，因此 RoI Pooling 对任意尺寸的输入都输出相同尺寸的输出。

\paragraph{Loss 函数}
Fast R-CNN 的 loss 为多任务 loss，包括分类和回归两部分，具体形式为：
\begin{align}
  L & = L_{\mathrm{cls}}(p, u) + \lambda [u \geq 1] L_{\mathrm{loc}}(t^u, v) \\ 
    & = -\mathrm{log}\,p_u + \sum_{i \in {x, y, w, h}} \mathrm{smooth}_{L_1}(t_i^u - v_i)
\end{align}

上式中计算了所有样本的分类 loss 和正样本的回归 loss。其中回归真值 $t^u$ 的计算方
法为\citerb{2013-RCNN}：
\begin{align}
  t_x & = (G_x - P_x) / P_w \\
  t_y & = (G_y - P_y) / P_h \\
  t_w & = \mathrm{log} (G_w/P_w) \\
  t_h & = \mathrm{log} (G_h/P_h)
\end{align}

上式中，$G$ 和 $P$ 分别代表 Ground Truth 和 Proposal 对应的值，因此 $t$ 相当于二
者之间的一种变换关系，Fast R-CNN 网络回归部分输出的 $v$ 与 $t$ 一样，\textbf{也是
  变换关系，而非直接预测检测框的位置}。回归部分采用 Smooth $L_1$ loss 的原因，原
文中解释是对偏差较大的点的敏感性低，因此不容易出现梯度爆炸问题，网络更容易训练。

\paragraph{正负样本}
计算分类 loss 时需要判断 proposal 的正负样本属性，具体标准为：

\begin{itemize}
  \item 正样本：与任一 GT 的 IoU $ \geq $ 0.5。
  \item 负样本：与所有 GT 的最大 IoU 在 $ [0.1, 0.5) $ 区间。
\end{itemize}

文中解释负样本的 IoU 下限取为 0.1 相当于做了难样本挖掘（HEM），因为 IoU 小于 0.1
的 proposal 可以认为是简单样本，训练时只用较难的样本。

\paragraph{训练}
训练时每个 batch 包含 2 张图，每张图取 64 个 proposal，相当于每个 batch 有 128
个 proposal，其中正负样本比例为 1:3。

\subsection{Faster R-CNN}
\label{subsec:Faster-R-CNN}

Faster R-CNN 是目标检测领域最经典的论文之一，文中提出了候选区域提取网络（Region
Proposal Network，RPN），可以直接利用 CNN 生成 proposal 以替代 selective search
等方法，同时通过共享 backbone，将 RPN 和 Fast R-CNN 合并成一个统一的 end-to-end
的网络，相比 Fast R-CNN 大幅提高了训练和测试速度。

\paragraph{RPN 网络结构} 
RPN 网络最开始是 CNN backbone，经过一个 $3 \times 3$ 的卷积层得到 feature
map，然后分别用一个 $1 \times 1$ 的卷积层 + Softmax 层的分类器得到分类分数（只
有\textbf{两类}，即前景类和背景类），同时再用一个 $1 \times 1$ 的卷积层得
到 anchor 到 GT 的变换（$t_x, t_y, t_w, t_h$四个值）。Faster R-CNN 最终的网络结构
是两个共享 backbone 的 RPN 和 Fast R-CNN 的组合。

\paragraph{RPN 网络 loss 函数} 
RPN 网络的 loss 函数和 Fast R-CNN 网络的非常类似，都包括分类和回归两项，区别
是 Fast R-CNN 一般为多分类，用 softmax loss；而 RPN 网络只是二分类，可以直接用交
叉熵 loss。

\paragraph{RPN 网络正负样本} 
RPN 计算分类 loss 时需要判断 anchor 的正负样本属性，具体标准为：

\begin{itemize}
  \item 正样本：与任一 GT 的 IoU $ \geq $ 0.7，以及在所有 anchor 中与某个 GT 的 IoU
    最大。
  \item 负样本：与所有 GT 的最大 IoU $ \leq $ 0.3。
  \item 忽略样本：与所有 GT 的最大 IoU 在 $(0.3, 0.7)$ 区间。
\end{itemize}

训练时每个 batch 包含 1 张图的 256 个 anchor，其中正负样本比例为 1:1。如果正样本
数不足 128，用负样本填充，保证一个 batch 的 anchor 数为 256。

\paragraph{训练方法}

Faster R-CNN 的训练方法一般包括 4 步交替训练法和近似联合训练法，主要介绍 4 步交
替训练法的具体步骤：

\begin{enumerate}
  \item Backbone 采用 pretrain model 权重初始化，训练 RPN。
  \item Backbone 采用 pretrain model 权重初始化，利用第 1 步 RPN 生成的 proposal，训练 Fast R-CNN。
  \item Backbone 采用第 2 步得到的权重初始化，固定 backbone，只 fine tune RPN 新增的层。
  \item Backbone 采用第 2 步得到的权重初始化，固定 backbone，利用第 3 步生成的
    proposal，只 fine tune Fast R-CNN 新增的层。
\end{enumerate}

通过以上四步即可得到 RPN 和 Fast R-CNN 共享 backbone 的 Faster R-CNN 网络。

\paragraph{RPN 后处理}
由于 RPN 生成的 proposal 有大量的重复区域，因此需要先进行后处理才能作为 Fast
R-CNN 的输入，后处理的步骤为：

\begin{enumerate}
  \item 取 RPN 网络生成的分数最高的 top $N_{\mathrm{pre}}$ 个 proposal。
  \item 给定一个 IoU 阈值（例如 0.7），对第 1 步的所有 proposal 做 NMS。
  \item 取第 2 步 NMS 之后分数最高的 top $N_{\mathrm{post}}$ 个 proposal。
\end{enumerate}

需要强调的是，后处理得到 proposal 后，后续训练就不再需要 RPN 的分数了，proposal 正负样本的
判断与 RPN 分数无关，\textbf{只与其与 GT 的 IoU 有关}。

\section{FPN}
\label{sec:FPN}

FPN 的核心思想是融合不同尺度的 feature 得到 feature 金字塔，之后进行多尺度预
测。FPN 及不同方法的对比如图~\ref{fig:FPN}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/FPN.pdf}
  \caption{FPN 与其他方法对比}
  \label{fig:FPN}
\end{figure}

\begin{itemize}
  \item 图(a)为传统的图像金字塔方法，该方法的问题是速度很慢，因为要进行 $n$ 张
    图片的前传。
  \item 图(b)为 Faster R-CNN 采用的方法，从单个 feature map 进行预测，问题是未充分
    利用不同 feature map 的信息。
  \item 图(c)为 SSD 采用的方法，从多个 feature map 分别预测，问题是未进行
    feature map 信息的融合。
  \item 图(d)为 FPN 采用的方法，先融合不同 feature map 信息，再从多尺度进行预测。
\end{itemize}

\paragraph{FPN 不同 feature map 融合 block}
FPN 中不同 feature map 融合的 block 是将深层小尺寸 feature map 进行 2 倍上采样，
同时将其上一层 feature map 经过 $1 \times 1$ 的卷积，使其与上采样后的 feature
map 的通道数相同，再将二者进行 element-wise 相加，再经过一个 $3 \times 3$
的卷积得到融合后的 feature map。

\paragraph{FPN 检测 head}
所有尺寸进行预测的检测 head 均共享权重，且输出的通道数均为 256，同时 head
中没有非线性层。

\paragraph{FPN 在 RPN 上的应用}

\begin{itemize}
  \item 加入 FPN 结构的 RPN 从 5 个尺度分别预测，与 SSD 类似，15 个预设尺寸的
    anchor 分别放在 5 个尺度的 feature map，每层 feature map 上有 3 个与其尺寸匹
    配的 anchor。
  \item Anchor 的正负样本标准与 Faster R-CNN 相同，GT 不再分配到不同尺度，而是直
    接和所有 anchor 计算 IoU，相当于 GT 和 anchor 进行匹配，等效将 GT 分配到不同
    尺度。
\end{itemize}

\paragraph{FPN 在 Fast R-CNN 上的应用}

Fast R-CNN 应用 FPN 时，主要需要根据 proposal 的尺寸分配不同 scale，利用 $ k =
\lfloor k_0 + \mathrm{log}_2 ( \sqrt{wh}/224 ) \rfloor$，即根据 proposal 的面积将
其分配到不同尺度的 feature map，面积越大分配的 feature map 越深，反之越浅。

\section{Faster R-CNN 的改进}
\label{sec:faster-improve}

\subsection{RoI Pooling 层的改进}
\subsubsection{Mask R-CNN}

\subsection{检测 head 的改进}
Faster R-CNN 中的检测 head 指的是 Fast R-CNN 中每个 RoI 之后接的网络，包括两个全
连接层，以及后面分类和回归分别对应的两个 $1 \times 1$ 的卷积层。本小节主要介绍对
Faster R-CNN 的检测 head 进行改进的相关工作。

\subsubsection{R-FCN}
文献\citerb{2016-R-FCN}中将 Faster R-CNN 中每个 RoI 后面接的检测 head 的全连接层，
替换为全卷积网络 + Position Sensitive RoI Pooling(PS-RoI) 层 + 全局平均池化层，模
型速度有2.5-20 倍的提升。

\paragraph{R-FCN 的结构}

\begin{itemize}
  \item 在 Backbone 得到的 2048 通道的 feature map 之后接一个 $1 \times 1$ 的卷积降
    为 1024 通道的 feature map，称为 FM-1024。
  \item 分类 head：FM-1024 后接 $(C+1)k^2$ 通道的 $1 \times 1$ 卷积，得到
    $(C+1)k^2$ 通道的 feature map，再接 PS-RoI Pooling 层得到 $(C+1) \times k
    \times k$ 的 feature，再接平均池化得到 $(C+1)$ 维向量，最后接 Softmax 得到
    $(C+1)$ 个分类分数。 
  \item 回归 head：与分类 head 类似，FM-1024 后接 $4$ 通道的 $1 \times 1$
    卷积，得到$4$ 通道的 feature map，再接 PS-RoI Pooling 层得到 $4
    \times k \times k$ 的 feature，再接平均池化得到 $4$ 维向量，分别对应 $x, y,
    w, h$ 的变换值。
\end{itemize}

R-FCN 中，PS-RoI Pooling 所用的 feature map 与 RPN 所用的 feature map 并不是同一
个。

\paragraph{PS-RoI Pooling 层}
PS-RoI Pooling 和 RoI Pooling 的过程十分类似，区别在于 PS-RoI 在做 pooling 时，是
根据 pooling 区域在 RoI 中的位置，选择对应通道 feature map 的对应位置做 pooling，
而非对所有 feature map 的所有位置都做 pooling。

\paragraph{R-FCN 的损失函数和 RoI 正负样本判据}
与 \hyperref[subsec:Fast-R-CNN]{Fast R-CNN} 相同。

\subsubsection{Light-Head R-CNN}
Light-Head R-CNN 首先分析了影响 Faster R-CNN 和 R-FCN 模型速度的原因\citerb{2017-Light-head}：

\begin{itemize}
  \item Faster R-CNN：计算量主要集中在每个 RoI sub-network 的两个全连接层。
  \item R-FCN：计算量主要集中在 PS-RoI Pooling 层需要的 $(C+1+4)k^2$ 个 feature
    map 之前的卷积，因为 feature map 数量很多。
\end{itemize}

Light-Head R-CNN 的检测 head 综合借鉴了 Faster R-CNN 和 R-FCN 的模型，用通道数较
少的 feature + pooling + 一个全连接的轻量 head 提高模型速度。三种模型的结构对比如
图~\ref{fig:light-head}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/Light-Head-R-CNN.pdf}
  \caption{Faster R-CNN/R-FCN/Light-Head R-CNN 结构对比}
  \label{fig:light-head}
\end{figure}

\paragraph{Light-head R-CNN 中 PS-RoI pooling 的 feature map}
通过在 $C_5$ feature map 后加分离卷积得到 PS-RoI pooling 需要的 feature map，即
加入两个对称的组合卷积分支：

\begin{itemize}
  \item $k \times 1 \times C_{\mathrm{in}} \times C_{\mathrm{mid}}$ + $1 \times k
    \times C_{\mathrm{mid}} \times C_{\mathrm{out}}$
  \item $1 \times k \times C_{\mathrm{in}} \times C_{\mathrm{mid}}$ + $k \times 1
    \times C_{\mathrm{mid}} \times C_{\mathrm{out}}$
\end{itemize}

文中卷积核的尺寸非常大，参数 $k=15$，但输出通道数相比 R-FCN 减少很多，只有 $10
\times k \times k$，其中 $k$ 为 PS-RoI Pooling 的尺寸，而 R-FCN 中则需要 $(C+1)
\times k \times k$ 个通道的 feature map。

\paragraph{R-CNN 子网络}
将 Faster R-CNN 中的两个全连接层简化为一个输出为 2048 的全连接层，同时将分类的全
连接层的输出减少为 4 维，即所有类别共享输出结果，不再单独输出每个类别的结果。

\subsubsection{Double-Head R-CNN}
Double-head R-CNN 首先分析了两种获得 RoI feature 的方法\citerb{2019-Double-head}：

\begin{itemize}
  \item RoI pooling 后接两个全连接层，得到维度为 $C_{\mathrm{out}}$ 的 feature。
  \item RoI pooling 后接两个卷积层，得到通道数为 $C_{\mathrm{out}}$ 的 feature
    map，再做全局平均池化，得到维度为 $C_{\mathrm{out}}$ 的 feature。
\end{itemize}

文中经过实验对比分析，发现经过全连接层得到的 feature 更适合分类，而卷积层得到的
feature 更适合回归。

\paragraph{损失函数}
Double-head R-CNN 的训练采用 end-to-end 的联合训练，其损失函数为：
\begin{equation}
  \label{equ:double-head-loss}
  \mathcal{L} = \mathcal{L}^{\mathrm{fc}} + \mathcal{L}^{\mathrm{conv}} + \mathcal{L}^{\mathrm{rpn}}
\end{equation}

其中 $\mathcal{L}^{\mathrm{fc}}, \mathcal{L}^{\mathrm{conv}},
\mathcal{L}^{\mathrm{rpn}}$ 分别表示全连接 head、卷积 head 和 RPN 的 loss，两个
head 的 loss 又分别包含分类和回归两部分：
\begin{align}
  \label{equ:double-head-fc-loss}
  \mathcal{L}^{\mathrm{fc}} & = \lambda^{\mathrm{fc}}L_{\mathrm{cls}}^{\mathrm{fc}} + (1-\lambda^{\mathrm{fc}})L_{\mathrm{reg}}^{\mathrm{fc}} \\
  \label{equ:double-head-conv-loss}
  \mathcal{L}^{\mathrm{conv}} & = \lambda^{\mathrm{conv}}L_{\mathrm{cls}}^{\mathrm{conv}} + (1-\lambda^{\mathrm{conv}})L_{\mathrm{reg}}^{\mathrm{conv}}
\end{align}

\paragraph{权重最优值}
文中经过寻优，得到的权重最优值为 $\lambda^{\mathrm{fc}} = 0.7,
\lambda^{\mathrm{\mathrm{conv}}} = 0.0$，注意卷积 head 的 feature 完全不学分类，只
学回归时最优。

\paragraph{分类分数}
文中对比了四种不同的利用全连接和卷积 feature 分类分数计算最终分类分数的方法，分别
是$s^{\mathrm{fc}}, (s^{\mathrm{fc}} + s^{\mathrm{conv}})/2,
\mathrm{max}(s^{\mathrm{fc}}, s^{\mathrm{conv}}), s^{\mathrm{fc}} +
s^{\mathrm{conv}}(1-s^{\mathrm{fc}})$，四种方法对应的模型性能 差别不大，最后一种
方法性能最好。

\chapter{单阶段方法}

\section{YOLO 系列}
\label{sec:YOLO}

\subsection{YOLO v1}
\label{subsec:YOLOv1}
YOLO v1 是目标检测单阶段方法的开创性工作之一，文中将检测问题刻画为回归问题，没有
任何分类的部分\citerb{2015-YOLO-v1}。

\paragraph{检测方法}

\begin{enumerate}
  \item 将整张图片划分为 $S \times S$ 个网格，每个网格预测 $ B $ 个检测框和 $ C $
    个条件概率 $ \mathrm{Pr}(\mathrm{Class}_i|\mathrm{Object}) $。
  \item 每个检测框共包括 5 个值 $x, y, w, h$ 和 confidence。其中 $x, y$为中心位
    置，$w, h$ 为长和宽（相对图片长宽的归一值），
    confidence 为$\mathrm{Pr}(\mathrm{Object}) \times
    \mathrm{IoU}^{\mathrm{truth}}_{\mathrm{pred}}$，inference 时直接将 confidence乘
    以该网格对应的条件概率得到最终的分数。网络的输出维度为 $ S \times S \times (B
    \times 5 + C) $。
\end{enumerate}

\paragraph{Backbone}

YOLO v1 的 backbone 没有采用改造后的经典分类网络，而是采用结构为 24 个卷积层 + 2
个全连接层的自定义网络。训练时，先将前 20 个卷积层 + 平均池化层组成的网络
在 ImageNet 数据集上进行预训练，输入尺寸为 $224 \times 224$，在检测时将输入尺寸扩
大为 $448 \times 448$。与此同时，为避免过拟合，第一个全连接层后加了一个 $p=0.5$
的 dropout 层。

\paragraph{Loss 函数}

\begin{align}
  \label{equ:yolo-v1-loss}
  \begin{split}
    L = & \, \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left [ \left (x_i - \hat{x}_i \right )^2 + \left (y_i - \hat{y}_i \right )^2 \right ] \\
    & \, + \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left [ \left(\sqrt{w_i} - \sqrt{\hat{w}_i} \right)^2 + \left (\sqrt{h_i} - \sqrt{\hat{h}_i} \right )^2 \right ]  \\
    & \, + \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{obj}} \left( C_i - \hat{C}_i \right)^2  \\
    & \, + \lambda_{\mathrm{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathds{1}_{ij}^{\mathrm{noobj}} \left( C_i - \hat{C}_i \right)^2  \\
    & \, + \sum_{i=0}^{S^2} \mathds{1}_{i}^{\mathrm{obj}} \sum_{c \in \mathrm{classes}} \left( p_i(c) - \hat{p}_i(c) \right)^2
  \end{split}
\end{align}

\begin{enumerate}
  \item Loss 函数共包括三部分：第一部分包括前两项，是检测框位置的 loss；第二部分包
    括中间两项，是检测框分数的 loss；第三部分包括最后一项，是网格类别概率的 loss。所
    有的 loss 均为 $L_2$ 形式。
  \item 检测框位置 loss 权重 $\lambda_{\mathrm{coord}}$ 提高到 5，同时将不含 GT 的
    网格中检测框分数 loss 的权重 $\lambda_{\mathrm{noobj}}$ 降为 0.5。
  \item 只有与 GT IoU 最大的检测框才会产生检测框位置 loss，只有网格中包含 GT 中
    心才产生网格类别概率 loss。
\end{enumerate}

\subsection{YOLO v2}
\label{subsec:YOLOv2}
YOLO v2 在 YOLO v1 的基础上做了一系列改进\citerb{2016-YOLO-v2}：

\begin{enumerate}
  \item 引入 BN：所有卷积层之后都加入 BN 层，由于 BN 层有正则化作用，因此可以去掉
    YOLOv1 中全连接层之后的 dropout 层。
  \item 改变预训练尺寸：YOLO v1 中预训练时图片输入尺寸为 $224 \times 224$，而检
    测时图片的输入尺寸为 $448 \times 448$，v2 中将预训练时的输入尺寸也改为 $448
    \times 448$，但网络实际的输入尺寸为 $416 \times 416$。
  \item 引入 anchor：参考 Faster R-CNN \cite{2015-Faster-RCNN}，YOLO v2 中同样引
    入 anchor 的概念，即网络的输出为 anchor 到 GT 的变换，同时每个 anchor 分别预
    测类别概率和前景分数，而不是一个网格只预测一个类别概率，这样就可以避免 v1 中
    每个网格只能预测一个类别的问题。
  \item Anchor 尺寸聚类：利用 k-means 算法将 GT 聚类，得到 k 个 anchor 尺寸的先
    验。聚类时距离定义为 $d = 1 - \mathrm{IoU}(\mathrm{box}, \mathrm{centroid})$。
  \item 预测相对位置：YOLO v2 输出的检测框的坐标是相对网格的偏差，而非与
    Faster R-CNN 中相同的变换，这样可以将 anchor 的中心限制在该网格内。在网络输
    出后加入 sigmoid 函数即可实现将任意输入压缩至 0 到 1 之间。
  \item 特征融合：将尺寸为 $26 \times 26$ 的 feature map 与尺寸为 $13 \times 13$
    的 feature map 进行融合，具体方法是将 $26 \times 26 \times 512$ 的 feature
    map 变换为 $13 \times 13 \times 2048$，再和 $13 \times 13$ 的 feature map 拼
    接。
  \item 多尺度训练：训练时采用多尺度训练，即图片输入尺寸为 320 到 608 之间，步长
    为 32 的随机数。
  \item 新的 backbone：采用新的 backbone Darknet-19，包含 19 个卷积层和 5 个最大
    池化层。
\end{enumerate}

\subsection{YOLO v3}
\label{subsec:YOLOv3}
YOLO v3 在 YOLO v2 的基础上做了部分改进\citerb{2018-YOLO-v3}：

\begin{enumerate}
  \item Anchor loss 的计算：每一个 GT 分配与其 IoU 最大的 anchor，该 anchor 对应的
    前景分数为 1，如果不是 IoU 最大的 anchor 且与某个 GT 的 IoU 大于 0.5，则
    该 anchor 会被忽略，即不产生前景分数 loss。同时，没有 GT 匹配的 anchor 也不产生
    检测框位置和类别 loss，只计算前景分数 loss。
  \item Loss 类型：将 Softmax loss 改为多个 sigmoid loss，一个 anchor 可以同时对
    应多个类别。
  \item 多尺度特征融合：采用类似 FPN\cite{2016-FPN} 的结构，将深层小尺寸 feature
    map 进行上采样后，与浅层大尺寸 feature map 相加，作为新的 feature map，文
    中共有 3 个尺度。
  \item Anchor 按尺度分配：YOLO v3 中共有 9 种尺寸的 anchor，根据大小分配到不同的
    尺度。
  \item 新的 backbone：采用新的 backbone Darknet-53，包含 53 个卷积层，其 top-5
    精度与 ResNet-152 相当，速度快 1 倍。
\end{enumerate}

\section{SSD 系列}
\label{sec:SSD}

\subsection{SSD}
\label{subsec:SSD}

SSD 是目标检测单阶段方法的经典工作之一，直观上可以将 SSD 看成多分类 + 多 feature
map 预测的 RPN\cite{2015-SSD}。

\paragraph{网络结构} 
SSD 网络的 backbone 采用 VGG-16，其后接了若干卷积层。检测 head 是一个 $3 \times
3$ 的卷积层，分别接在不同尺寸的 feature map 上，即进行多尺度预测。

\paragraph{Loss 函数}
与 Fast R-CNN 相同。

\paragraph{正负样本} 
SSD 中引入了和 anchor 类似的 default box，其正负样本的标准为：

\begin{itemize}
\item 正样本：包括两类，第一类是 GT 对应的 IoU 的 default box，第二类是与 GT 的
  最大 IoU $ \geq 0.5 $。 
\item 负样本：与 GT 的最大 IoU $ < 0.5 $。
\end{itemize}

\paragraph{Default box 尺寸} 
SSD 使用了多尺度预测，不同尺寸 feature map 上的 default box 也采用了不同的预设尺
寸，这部分原文和源代码不一致，简单的原则是尺寸大的浅层 feature map 上的 default
box 尺寸小，反之尺寸大。具体请参考
\href{https://github.com/weiliu89/caffe/blob/ssd/examples/ssd/ssd_pascal.py}{这里}。

\paragraph{训练} 
SSD 训练时的正负样本比为 1:3，在训练时使用了难样本挖掘（HEM），即只选择 loss 最高
的负样本进行计算。

\subsection{DSSD}
\label{subsec:DSSD}

DSSD 是 SSD 的扩展版，思想与 \hyperref[sec:FPN]{FPN} 类似，同样对不同尺度的
feature map 进行融合以提高模型性能\citerb{2017-DSSD}。

\paragraph{DSSD 的特征融合}
DSSD 的特征融合模块包括：

\begin{itemize}
  \item 深层 feature map：先经过 $2 \times 2$ 的\hyperref[subsec:deconv]{反卷积}，
    再接 $3 \times 3$ 的卷积和 BN，输出通道数为 512。
  \item 浅层 feature map：先经过一个标准的卷积-BN-ReLU，再接 $3 \times 3$ 的卷积
    和 BN，输出通道数同样为 512。
  \item 融合：将深层和浅层 feature map 做 element-wise 乘积，再接 ReLU，得到融合
    后的 feature map。
\end{itemize}

\paragraph{DSSD 对预测模块的改进}
SSD 中，预测模块（即 $3 \times 3$ 卷积）直接接在对应卷积层的 feature map 上，
DSSD 中进行了改进：

\begin{itemize}
  \item 原始 feature map 先经过 3 个 $1 \times 1$ 的卷积，输出通道数分别为 256，
    256 和 1024，得到 feature map 1。
  \item 原始 feature map 直接经过 1 个输出通道数为 1024 的 $1 \times 1$ 的卷积，
    得到 feature map 2。
  \item 将 feature map 1 和 feature map 2 做 element-wise 求和，得到最终的
    feature map，后接 $3 \times 3$ 卷积分别进行分类和回归。
\end{itemize}

\section{RetinaNet 系列}

\subsection{RetinaNet}
\label{sub:RetinaNet}

RetinaNet 是单阶段目标检测里程碑式的论文，综合吸收了 Faster R-CNN、SSD 和 FPN 中
的精华，同时提出新颖的 focal loss，性能超过了当时的两阶段模型，一举扭转了当时比较
流行的目标检测模型双阶段准、单阶段快的观点\citerb{2017-RetinaNet}。

\paragraph{Focal loss 的应用}
RetinaNet 训练时分类部分的 loss 采用 focal loss，扫参结果 $\alpha = 0.25, \gamma
= 2$ 时效果最好。由于正样本数量很少，因此对分类器的初始化也做了调整，将最后一个
卷积层的偏置的初值设为 $-\mathrm{log}((1 - \pi)/ \pi)$，其中 $\pi$ 为正样本概率，
原文中取为 0.01。应用 focal loss 后，所有 anchor 都参与计算 loss，不再需要进行采
样。

\paragraph{Anchor 参数}
RetinaNet 同样采用了 FPN 结构，分别从 $P_3$ 到 $P_7$ 五个尺度进行预测，对应的
anchor 面积为 $32^2$ 到 $512^2$。每个尺度上有三个长宽比例和三种不同尺寸 anchor
的组合，共 9 种 anchor。

\paragraph{正负样本}
正负样本判断标准如下：
\begin{itemize}
\item 正样本：与任一 GT 的 IoU $\geq$ 0.5。
\item 负样本：与所有 GT 的最大 IoU $ < $ 0.4。
\item 忽略样本：与所有 GT 的最大 IoU 在 $[0.4, 0.5)$。
\end{itemize}

\paragraph{分类 head}
在 FPN 得到的通道数为 $C$ 的 feature map 上，先接 4 个通道数为 $C$ 的
$3 \times 3$ 的包含 ReLU 的卷积，再接 1 个 channel 数为 $KA$ 的 $3 \times 3$ 的
卷积，其中 $K$ 为类别数，$A$ 为 anchor 数，最后再接 sigmoid 层得到最终的分数。

\paragraph{回归 head}
回归 head 与分类 head 的基本相同，除了最后不会接 sigmoid，因为回归部分可能输出负
值。此外，回归 head 只输出一个变换关系，而非每个类别输出一个变换关系。需要说明的
是，回归 head 和分类 head 虽然结构相同，但并不共享参数。

\paragraph{Inference}
Inference 时 FPN 每个尺度分数阈值卡 0.05，然后取分数最高的前 1000 个结果，再进行
阈值为 0.5 的 NMS 得到最终结果。

\chapter{Anchor Free 方法}
自从 Faster R-CNN 引入 anchor 的概念后，几乎所有的目标检测文章中都应用了这一方法，
但使用 anchor 会引入 anchor 个数和尺寸等超参，增加了调参工作量。Anchor free 检测
方法不需要使用 anchor，是目标检测的一个新方向。

\section{CornerNet}
\label{sec:CornerNet}
CornerNet 是 anchor free 方法的代表作之一\citerb{2018-CornerNet}，与传统目标检测
预测目标框位置和长/宽不同，CornerNet 直接预测左上/右下角点及配对关系。

\paragraph{CornerNet 网络结构}
CornerNet 的网络结构和预测模块的结构如图~\ref{fig:CornerNet-network}~和图~\ref{fig:CornerNet-network}~所示：

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/CornerNet-网络结构.pdf}
  \caption{CornerNet 网络结构}
  \label{fig:CornerNet-network}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.8\textwidth]{images/目标检测/CornerNet-预测模块.pdf}
  \caption{CornerNet 的预测模块}
  \label{fig:CornerNet-network}
\end{figure}

网络的三个输出分别为：

\begin{itemize}
  \item 角点 heatmap：尺寸为原图下采样 stride 等于 n 的 heatmap，每个类
    别 1 个，heatmap上的值在 $[0, 1]$ 之间。
  \item 角点配对 embedding：用于左上/右下间角点的配对，要求两个角点的 embedding
    值小于一定阈值，所有类别共享相同的 embedding。
  \item 角点精修 offset：输出角点坐标的修正量，所有类别共享相同的 offset。
\end{itemize}

\paragraph{Corner Pooling 层}
Corner Pooling 层是 CornerNet 中为了提取 feature map 上左上和右下点提出的一种新
的池化层。以左上点的 corner pooling 为例，从该点出发，分别向右/向下找到本行/本列
最大值，将二者相加作为该点的值。实际计算时，可以由右向左、由下向上分别计算，这样
只需保留当前最大值。

\paragraph{损失函数}
CornerNet 的损失函数包括三个输出对应的损失函数：
\begin{equation}
  \label{eq:cornernet-loss}
  L = L_{\mathrm{det}} + \gamma L_{\mathrm{off}} + (\alpha L_{\mathrm{pull}} + \beta L_{\mathrm{push}}) 
\end{equation}

\begin{itemize}
  \item heatmap 损失函数 $L_{\mathrm{det}}$：类似 focal loss 形式，但 focal loss
    中 label 只有 0 和 1 两种，而 CornerNet 中 label 是 $[0, 1]$ 区间的连续值：
    \begin{equation}
      \label{equ:cornernet-det-loss}
      L_{\mathrm{det}} = -\frac{1}{N} \sum_{c=1}^{C} \sum_{i=1}^{H} \sum_{j=1}^{W}
      \left\{
        \begin{array}{lr}
           (1-p_{cij})^{\alpha}\mathrm{log}\,(p_{cij}) & y_{cij} = 1 \\
           (1-y_{cij})^{\beta} (1-p_{cij})^{\alpha} \mathrm{log}\,(p_{cij}) & y_{cij} < 1 \\
        \end{array}
      \right.
    \end{equation}
    上式中 $y_{cij}$ 的值在 GT 左上/右下角点为 1，但并非除角点外均为 0，而是存在一
    个衰减系数 $e^{-\frac{9(x^2+y^2)}{2\sigma^2}}$，其中 $\sigma$ 的确定方法为：
    在角点附近该范围以内的点组成的方框与 GT 的 IoU 均大于 0.3。 
  \item offset 损失函数 $L_{\mathrm{off}}$：stride 为 n 时，输入上的点 $(x, y)$
    对应的值为 $( \lfloor \frac{x}{n} \rfloor, \lfloor \frac{y}{n} \rfloor)$，
    offset 部分的真值 $\mathbf{o}_k = \left( \frac{x}{n} - \lfloor \frac{x}{n}
      \rfloor, \frac{y}{n} - \lfloor \frac{y}{n} \rfloor \right)$，loss 采用
    Smooth $L_1$ loss。
  \item embedding 损失函数 $(\alpha L_{\mathrm{pull}} + \beta
    L_{\mathrm{push}})$：类似 triplet loss，同一 GT 的 embedding 尽可能小，不
    同 GT 的尽可能大：
    \begin{align}
      \label{equ:cornernet-em-loss-pull}
      L_{\mathrm{pull}} & = \frac{1}{N} \sum_{k=1}^{N} \left[ (e_{t_k} - e_k)^2 + (e_{b_k} - e_k)^2 \right] \\
      \label{equ:cornernet-em-loss-push}
      L_{\mathrm{push}} & = \frac{1}{N(N-1)} \sum_{k=1}^{N} \sum_{\substack{j=1 \\ j \neq k}}^{N} \mathrm{max} (0, 1-|e_k-e_j|)
    \end{align}
\end{itemize}

Offset 和 embedding loss 只在 GT 的角点位置才计算，其他位置均为 0。

\paragraph{CornerNet 的测试}
\begin{itemize}
  \item 获得角点：先对 heatmap 做 $3 \times 3$ 的 max pooling，然后挑选所有类
    别 heatmap 中 top 100 的左上点和右下点。
  \item 精修角点：利用 offset 精修角点位置。
  \item 获得左上/右下点对：利用 embedding 计算点对，筛掉 embedding 相差大于 0.5
    或两个角点不属于同一个类别的点对，获得最终结果，最终分数为左上/右下角点
    heatmap 对应点的平均值。
\end{itemize}

\section{ExtremeNet}
\label{sec:ExtremeNet}
ExtremeNet\citerb{2019-ExtremeNet}借鉴了 CornerNet 的思想，预测的是四个方向上的极值
点和中心点。

\paragraph{ExtremeNet 网络结构}
ExtremeNet 沿用了 CornerNet 中预测 heatmap 和 offset map 的结构，共预测上、下、
左、右及中心 5 个 heatmap，以及除中心外共 $4 \times 2$ 个 offset map。正负样本及
loss 也和 CornerNet 相同。

\paragraph{极值点的组合}
CenterNet 中利用 embedding 信息关联左上/右下角点，ExtremeNet 中获得极值点组合的
方法是：

\begin{itemize}
  \item 获得上/下/左/右 heatmap 局部极值点：局部极值点满足的条件是值大
    于 $\tau_p=0.1$，且在周围 $3 \times 3$ 的区域内为最大值。
  \item 计算中心点：枚举所有局部极值点组合，计算中心点坐标，其对应的 heatmap 值需
    要大于 $\tau_c=0.1$。
\end{itemize}

\paragraph{Ghost box 抑制}
Ghost box 是指包含多个较小检测框的大的检测框，文中提出一种抑制 ghost box 的方法，
如果一个检测框内部包含检测框的分数之和大于其自身分数的 3 倍，则将其分数除以 2，
这个做法类似 Soft NMS。

\paragraph{边缘增强}
找到局部极值点后，分别沿水平/竖直方向找到单调递减的最外点，然后更新局部极值点的
值，$\tilde{Y}_m = \hat{Y}_m + \lambda_{\mathrm{aggr}}\sum_{i=i_0}^{i_1}Y_i^m$，
其中 $\lambda_{\mathrm{aggr}}=0.1$。

\section{CenterNet}
\label{sec:CenterNet}

CenterNet 和 ExtremeNet 类似，都出自 UT Austin 的 Zhou Xingyi，且同样借
鉴 CornerNet 的思路，但不再预测角点及其组合，而是直接预测中心点和物体的长和
宽\citerb{2019-CenterNet}。

\paragraph{CenterNet 网络结构和损失函数}
CenterNet 沿用了 CornerNet 中预测 heatmap 和 offset map 的结构，每个类别预测一个
中心点的 heatmap 及长和宽两个方向的 offset。此外还多预测长和宽方向检测框的尺寸，
除中心点 heatmap 外，offset 和尺寸所有类别共享同一个，loss 均为 Smooth $L_1$
loss，总的 loss 为：
\begin{equation}
  \label{equ:extreme-net-loss}
  L_{\mathrm{det}} = L_k + \lambda_{\mathrm{size}}L_{\mathrm{size}} + \lambda_{\mathrm{off}}L_{\mathrm{off}}
\end{equation}

其中 $\lambda_{\mathrm{size}}=0.1, \lambda_{\mathrm{off}}=1$。


%%% Local Variables:
%%% TeX-master: "../master"
%%% End:
